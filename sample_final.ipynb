{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# regular expression libreary\n",
    "import re\n",
    "# Alternative of Decontraction libreary(Faced Java issue)\n",
    "import contractions\n",
    "from textsearch import TextSearch\n",
    "\n",
    "import numpy as np\n",
    "# for calculate weighted levenshtein \n",
    "from weighted_levenshtein import lev, osa, dam_lev\n",
    "# nltk libreary for biagrams\n",
    "from nltk import word_tokenize, ngrams\n",
    "\n",
    "# this function sepreates sentences with .,!,?,\\n regular expression.\n",
    "def listSplit(name):\n",
    "    file = open(name, \"r\")\n",
    "    doclist = [ line.lower() for line in file ]\n",
    "    docstr = ''. join(doclist)\n",
    "    sentences = re.split(r'[.!?\\n]', docstr)\n",
    "    sentences = [x for x in sentences if x != '']\n",
    "    return sentences\n",
    "\n",
    "# Add contractions in sentances if necessary . Eg: I'd -> I would\n",
    "def expand_contractions(sens):\n",
    "    deContraction = []\n",
    "    for i,j in enumerate(sens):\n",
    "        deContraction.append(contractions.fix(j))\n",
    "    return deContraction\n",
    "\n",
    "# Seperate tokens from each sentences.\n",
    "def token_sept(sens):\n",
    "    tokens= []\n",
    "    for i,j in enumerate(sens):\n",
    "        tokens.append(j.split(' '))\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick all words from corpus whose size is (len(recognised_word) -1) or len(recognised_word) +1. \n",
    "# For example my rec_word is : hello len is 5. Then all letters from corpus of size 4 to 6 will take for dictonary error correction.\n",
    "def picked_words(expand_contractions,lenWord):\n",
    "    counts_word = []\n",
    "    for d in expand_contractions:\n",
    "        for j in d:\n",
    "            if len(j) >= lenWord-1 and len(j) <= lenWord+1:\n",
    "                counts_word.append(j)\n",
    "    return counts_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Typographic errors detection refered \"https://pdfs.semanticscholar.org/c64f/1bd3a1bd7f7fe4cadc469b4b94c45ad12b5d.pdf\" Research paper\n",
    "def edits1(word):\n",
    "    letters    = 'abcdefghijklmnopqrstuvwxyz'\n",
    "    split = []\n",
    "    deletes = []\n",
    "    transposes = []\n",
    "    replaces = []\n",
    "    inserts = []\n",
    "\n",
    "    for i in range(len(word)+1):\n",
    "        split.append([word[:i], word[i:]])\n",
    "\n",
    "    for i,j in split:\n",
    "        if j:\n",
    "            deletes.append(i + j[1:])\n",
    "\n",
    "    for i,j in split:\n",
    "        if len(j)>1:\n",
    "            transposes.append(i + j[1] + j[0] + j[2:])\n",
    "\n",
    "    for i,j in split:\n",
    "        if j:\n",
    "            for c in letters:\n",
    "                replaces.append(i + c + j[1:])\n",
    "\n",
    "\n",
    "    for i,j in split:\n",
    "        for c in letters:\n",
    "            inserts.append(i + c + j)\n",
    "\n",
    "    \n",
    "    return list(deletes+inserts+transposes+replaces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check all possiblities of Typographic errors in to the word picked.\n",
    "def result(final_select,picked_words):\n",
    "    data = []\n",
    "    for i in final_selection:\n",
    "        if i in picked_words:\n",
    "            data.append(i)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Answer with weighted levenshtein with characted differences.\n",
    "def data_print(answer,recWord):\n",
    "    substitute_costs = np.ones((128, 128), dtype=np.float64) \n",
    "    for i in answer:\n",
    "         print(\"The word may be : {} the change in char is of  : {} digits\".format(i,int(dam_lev(recWord, i, substitute_costs=substitute_costs))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# biagram function. Eg. 'Hello' -> ['he','el','ll','lo']\n",
    "def ngram(s1):\n",
    "    return list(ngrams(s1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove doubles into the biagram for calcuation purpus. refered in the same research paper : A. N-gram Analysis [3] Section\n",
    "def remove_double(s1):\n",
    "    count = 0\n",
    "    for (filename,filepath) in s1:\n",
    "        count = count + 1\n",
    "        for (filename1,filepath1) in s1[count:]:\n",
    "            if filename == filename1:\n",
    "                s1.remove((filename1,filepath1))\n",
    "    return s1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy count for 2 biagram.\n",
    "def accuracy_count(s1,s2):\n",
    "    data = []\n",
    "    for i,j in s1:\n",
    "        for k,l in s2:\n",
    "            if i==k and j==l:\n",
    "                data.append((i,j))\n",
    "    return (2*len(data)) / (len(s1)+len(s2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data fetch\n",
    "sentences = listSplit('europarl-v7.de-en.en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sentences creations.\n",
    "sentences = sentences[0:len(sentences)-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# identifie contractions.\n",
    "expand_contrac = expand_contractions(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert sentennces to tokens.\n",
    "tokens = token_sept(expand_contrac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "recWord = 'little'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pick all words from corpus according sto size.\n",
    "picked_words=picked_words(tokens,len(recWord))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking all possiblities of Typographic errors\n",
    "final_selection=edits1(recWord)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# results with uniquness between recognised word and corpus word\n",
    "answer = result(final_selection,picked_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The word may be : little the change in char is of  : 0 digits\n",
      "The word may be : little the change in char is of  : 0 digits\n",
      "The word may be : tittle the change in char is of  : 1 digits\n",
      "The word may be : little the change in char is of  : 0 digits\n",
      "The word may be : little the change in char is of  : 0 digits\n",
      "The word may be : little the change in char is of  : 0 digits\n",
      "The word may be : little the change in char is of  : 0 digits\n",
      "The word may be : little the change in char is of  : 0 digits\n",
      "Biagram --> word from corpus = little and recognises = little and accuracy is = 1.0\n",
      "Biagram --> word from corpus = little and recognises = little and accuracy is = 1.0\n",
      "Biagram --> word from corpus = little and recognises = tittle and accuracy is = 0.3333333333333333\n",
      "Biagram --> word from corpus = little and recognises = little and accuracy is = 1.0\n",
      "Biagram --> word from corpus = little and recognises = little and accuracy is = 1.0\n",
      "Biagram --> word from corpus = little and recognises = little and accuracy is = 1.0\n",
      "Biagram --> word from corpus = little and recognises = little and accuracy is = 1.0\n",
      "Biagram --> word from corpus = little and recognises = little and accuracy is = 1.0\n"
     ]
    }
   ],
   "source": [
    "# print the result with Weighted Levenshtein \n",
    "data_print(answer,recWord)\n",
    "# if the multiple answer is found then gives the output of all multiple word occurance with accuracy of biagram.\n",
    "for i in answer:\n",
    "    s1_N = ngram(i)\n",
    "    s2_N = ngram(recWord)\n",
    "\n",
    "    s1_rm = remove_double(s1_N)\n",
    "    s2_rm = remove_double(s2_N)\n",
    "\n",
    "    print('Biagram --> word from corpus = {} and recognises = {} and accuracy is = {}'.format(recWord,i,accuracy_count(s1_rm,s2_rm)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test case 1: \n",
    "    #  Biagram --> word from corpus = unetek and recognises = unitek and accuracy is = 0.4444444444444444\n",
    "\n",
    "# Test Case 2 :\n",
    "    # Biagram --> word from corpus = little and recognises = little and accuracy is = 1.0\n",
    "    # Biagram --> word from corpus = little and recognises = tittle and accuracy is = 0.3333333333333333"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
